{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a7a91e",
   "metadata": {},
   "source": [
    "# Shengyan Gao 4626-8392-42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e397e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz as gr\n",
    "\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5a5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13974329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e961e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7969990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2698274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data(tau,N,p,p0,corr,conf = True,flagX = False):\n",
    "   \n",
    "    nvar = p+2 \n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "    else: \n",
    "        conf_mult=1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1])\n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4777bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac89f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "            # use the right covariates in regression\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "        elif flagX==2:\n",
    "            # use some of the right covariates and some \"wrong\" ones\n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs1 = X[:,:np.int(p0/2)]\n",
    "            Xobs2 = X[:,-np.int(p0/2):]\n",
    "            covars = np.concatenate([T,Xobs1,Xobs2],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fe602",
   "metadata": {},
   "source": [
    "# 1a Experiments with no covariates in the DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e18fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.1 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"170pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 170.49 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 166.49,-112 166.49,4 -4,4\"/>\n",
       "<!-- Study Time(T) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Study Time(T)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"81.24\" cy=\"-90\" rx=\"64.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"81.24\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Study Time(T)</text>\n",
       "</g>\n",
       "<!-- Grade Outcome(Y) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Grade Outcome(Y)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"81.24\" cy=\"-18\" rx=\"81.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"81.24\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Grade Outcome(Y)</text>\n",
       "</g>\n",
       "<!-- Study Time(T)&#45;&gt;Grade Outcome(Y) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Study Time(T)&#45;&gt;Grade Outcome(Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.24,-71.7C81.24,-63.98 81.24,-54.71 81.24,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.74,-46.1 81.24,-36.1 77.74,-46.1 84.74,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f9908213fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"Study Time(T)\", \"Grade Outcome(Y)\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3f13a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 343.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 0 \n",
    "Nrange = range(10,1000,5)\n",
    "flagX=1\n",
    "N=500\n",
    "Y,Z,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e4ad170",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([Y,Z,X],axis=1)\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('part1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7d0c2",
   "metadata": {},
   "source": [
    "# When N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae9bb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7917392460008188, 0.19911386364232916)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "Yexp,T = fn_generate_data(tau,N,10,0,corr,conf = False)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6156fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const = np.ones([N,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2363ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   80.97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>1.80e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:04</td>     <th>  Log-Likelihood:    </th> <td> -140.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   284.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   290.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    1.7917</td> <td>    0.199</td> <td>    8.999</td> <td> 0.000</td> <td>    1.397</td> <td>    2.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0969</td> <td>    0.141</td> <td>    0.688</td> <td> 0.493</td> <td>   -0.183</td> <td>    0.376</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.120</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.571</td> <th>  Jarque-Bera (JB):  </th> <td>   0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.156</td> <th>  Prob(JB):          </th> <td>   0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.246</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.452\n",
       "Model:                            OLS   Adj. R-squared:                  0.447\n",
       "Method:                 Least Squares   F-statistic:                     80.97\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):           1.80e-14\n",
       "Time:                        01:03:04   Log-Likelihood:                -140.44\n",
       "No. Observations:                 100   AIC:                             284.9\n",
       "Df Residuals:                      98   BIC:                             290.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             1.7917      0.199      8.999      0.000       1.397       2.187\n",
       "const          0.0969      0.141      0.688      0.493      -0.183       0.376\n",
       "==============================================================================\n",
       "Omnibus:                        1.120   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.571   Jarque-Bera (JB):                0.658\n",
       "Skew:                          -0.156   Prob(JB):                        0.719\n",
       "Kurtosis:                       3.246   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b7418",
   "metadata": {},
   "source": [
    "# When N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4596e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0290623083236534, 0.06104221899773056)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "Yexp,T = fn_generate_data(tau,N,10,0,corr,conf = False)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "846d238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.525</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.525</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1105.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>1.05e-163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:04</td>     <th>  Log-Likelihood:    </th> <td> -1382.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2769.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   2779.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.0291</td> <td>    0.061</td> <td>   33.240</td> <td> 0.000</td> <td>    1.909</td> <td>    2.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0289</td> <td>    0.043</td> <td>   -0.670</td> <td> 0.503</td> <td>   -0.114</td> <td>    0.056</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.181</td> <th>  Durbin-Watson:     </th> <td>   1.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.336</td> <th>  Jarque-Bera (JB):  </th> <td>   2.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.092</td> <th>  Prob(JB):          </th> <td>   0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.122</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.525\n",
       "Model:                            OLS   Adj. R-squared:                  0.525\n",
       "Method:                 Least Squares   F-statistic:                     1105.\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):          1.05e-163\n",
       "Time:                        01:03:04   Log-Likelihood:                -1382.5\n",
       "No. Observations:                1000   AIC:                             2769.\n",
       "Df Residuals:                     998   BIC:                             2779.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             2.0291      0.061     33.240      0.000       1.909       2.149\n",
       "const         -0.0289      0.043     -0.670      0.503      -0.114       0.056\n",
       "==============================================================================\n",
       "Omnibus:                        2.181   Durbin-Watson:                   1.950\n",
       "Prob(Omnibus):                  0.336   Jarque-Bera (JB):                2.037\n",
       "Skew:                           0.092   Prob(JB):                        0.361\n",
       "Kurtosis:                       3.122   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.ones([N,1])\n",
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202f0e8",
   "metadata": {},
   "source": [
    "# Run a Monte Carlo experiment, and calculate the bias, RMSE and size for N=100 and N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552fc444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1384.66it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:11<00:00, 166.74it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,10,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960ea419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0036535040479215536, RMSE=0.20169451721500303, size=0.0525\n",
      "N=1000: bias=0.0003535870538214996, RMSE=0.06441122885052279, size=0.058\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18664b5d",
   "metadata": {},
   "source": [
    "# 1b Experiments with covariates in the DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f866fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.1 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"795pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 795.09 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 791.09,-112 791.09,4 -4,4\"/>\n",
       "<!-- study time (T) -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>study time (T)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63.04\" cy=\"-90\" rx=\"63.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">study time (T)</text>\n",
       "</g>\n",
       "<!-- grade outcome (Y) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>grade outcome (Y)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"350.04\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.04\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">grade outcome (Y)</text>\n",
       "</g>\n",
       "<!-- study time (T)&#45;&gt;grade outcome (Y) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>study time (T)&#45;&gt;grade outcome (Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.47,-77.68C158.01,-65.84 234.45,-47.19 288.1,-34.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"288.96,-37.5 297.85,-31.73 287.3,-30.7 288.96,-37.5\"/>\n",
       "</g>\n",
       "<!-- gender (X1) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>gender (X1)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"199.04\" cy=\"-90\" rx=\"55.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"199.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">gender (X1)</text>\n",
       "</g>\n",
       "<!-- gender (X1)&#45;&gt;grade outcome (Y) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>gender (X1)&#45;&gt;grade outcome (Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M229.6,-74.83C252.07,-64.42 282.88,-50.14 307.72,-38.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"309.31,-41.74 316.91,-34.36 306.37,-35.39 309.31,-41.74\"/>\n",
       "</g>\n",
       "<!-- class amount (X2) -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>class amount (X2)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"350.04\" cy=\"-90\" rx=\"77.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"350.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">class amount (X2)</text>\n",
       "</g>\n",
       "<!-- class amount (X2)&#45;&gt;grade outcome (Y) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>class amount (X2)&#45;&gt;grade outcome (Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M350.04,-71.7C350.04,-63.98 350.04,-54.71 350.04,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.54,-46.1 350.04,-36.1 346.54,-46.1 353.54,-46.1\"/>\n",
       "</g>\n",
       "<!-- intelligence (X3) -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>intelligence (X3)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"518.04\" cy=\"-90\" rx=\"72.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"518.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">intelligence (X3)</text>\n",
       "</g>\n",
       "<!-- intelligence (X3)&#45;&gt;grade outcome (Y) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>intelligence (X3)&#45;&gt;grade outcome (Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M482.42,-74.15C457.09,-63.6 422.85,-49.34 395.54,-37.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"396.78,-34.68 386.2,-34.07 394.09,-41.14 396.78,-34.68\"/>\n",
       "</g>\n",
       "<!-- health condition (X4) -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>health condition (X4)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"698.04\" cy=\"-90\" rx=\"89.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"698.04\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">health condition (X4)</text>\n",
       "</g>\n",
       "<!-- health condition (X4)&#45;&gt;grade outcome (Y) -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>health condition (X4)&#45;&gt;grade outcome (Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M637.43,-76.81C575.97,-64.44 481.08,-45.36 417.32,-32.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417.86,-29.07 407.37,-30.53 416.48,-35.93 417.86,-29.07\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f98ec7e4ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=gr.Digraph()\n",
    "g.edge(\"study time (T)\", \"grade outcome (Y)\")\n",
    "g.edge(\"gender (X1)\", \"grade outcome (Y)\")\n",
    "g.edge(\"class amount (X2)\", \"grade outcome (Y)\")\n",
    "g.edge(\"intelligence (X3)\", \"grade outcome (Y)\")\n",
    "g.edge(\"health condition (X4)\", \"grade outcome (Y)\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "138e1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 494.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = 0.5\n",
    "conf=False\n",
    "p = 10\n",
    "p0 = 30\n",
    "Nrange = range(10,1000,5) \n",
    "(nvalues,tauhats,sehats,lb,ub) = fn_run_experiments(tau,Nrange,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b13ef9",
   "metadata": {},
   "source": [
    "# When N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c97f7320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.9167817382539953, 4.936711196629323)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "Yexp,T = fn_generate_data(tau,N,10,30,corr,conf = False,flagX=0)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5155f5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.1508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.699</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:19</td>     <th>  Log-Likelihood:    </th> <td> -461.50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   927.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   932.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.9168</td> <td>    4.937</td> <td>   -0.388</td> <td> 0.699</td> <td>  -11.714</td> <td>    7.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.1330</td> <td>    3.491</td> <td>    0.897</td> <td> 0.372</td> <td>   -3.794</td> <td>   10.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.199</td> <th>  Durbin-Watson:     </th> <td>   2.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.905</td> <th>  Jarque-Bera (JB):  </th> <td>   0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.028</td> <th>  Prob(JB):          </th> <td>   0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.703</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                 -0.009\n",
       "Method:                 Least Squares   F-statistic:                    0.1508\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):              0.699\n",
       "Time:                        01:03:19   Log-Likelihood:                -461.50\n",
       "No. Observations:                 100   AIC:                             927.0\n",
       "Df Residuals:                      98   BIC:                             932.2\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -1.9168      4.937     -0.388      0.699     -11.714       7.880\n",
       "const          3.1330      3.491      0.897      0.372      -3.794      10.060\n",
       "==============================================================================\n",
       "Omnibus:                        0.199   Durbin-Watson:                   2.046\n",
       "Prob(Omnibus):                  0.905   Jarque-Bera (JB):                0.382\n",
       "Skew:                          -0.028   Prob(JB):                        0.826\n",
       "Kurtosis:                       2.703   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.ones([N,1])\n",
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a11f0",
   "metadata": {},
   "source": [
    "# When N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce022c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.73093278921404, 2.348191050730331)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "Yexp,T = fn_generate_data(tau,N,10,30,corr,conf = False,flagX=0)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5364e052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.524</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th>  <td> 0.112</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:19</td>     <th>  Log-Likelihood:    </th> <td> -5032.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>1.007e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>1.008e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    3.7309</td> <td>    2.348</td> <td>    1.589</td> <td> 0.112</td> <td>   -0.877</td> <td>    8.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.9792</td> <td>    1.660</td> <td>   -0.590</td> <td> 0.556</td> <td>   -4.237</td> <td>    2.279</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.647</td> <th>  Durbin-Watson:     </th> <td>   2.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.724</td> <th>  Jarque-Bera (JB):  </th> <td>   0.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.062</td> <th>  Prob(JB):          </th> <td>   0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.972</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     2.524\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):              0.112\n",
       "Time:                        01:03:19   Log-Likelihood:                -5032.3\n",
       "No. Observations:                1000   AIC:                         1.007e+04\n",
       "Df Residuals:                     998   BIC:                         1.008e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             3.7309      2.348      1.589      0.112      -0.877       8.339\n",
       "const         -0.9792      1.660     -0.590      0.556      -4.237       2.279\n",
       "==============================================================================\n",
       "Omnibus:                        0.647   Durbin-Watson:                   2.060\n",
       "Prob(Omnibus):                  0.724   Jarque-Bera (JB):                0.666\n",
       "Skew:                           0.062   Prob(JB):                        0.717\n",
       "Kurtosis:                       2.972   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.ones([N,1])\n",
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428701ce",
   "metadata": {},
   "source": [
    "# Run a Monte Carlo experiment, and calculate the bias, RMSE and size for N=100 and N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bca71af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:02<00:00, 825.75it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:14<00:00, 142.64it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c532ffdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0023845584490785527, RMSE=0.14893604134578892, size=0.0585\n",
      "N=1000: bias=-0.00030831010696697093, RMSE=0.0448708650899369, size=0.052\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee261e03",
   "metadata": {},
   "source": [
    "# 2a Experiments with no control for confounder in the DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22ed08cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.1 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"165pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 164.69 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 160.69,-184 160.69,4 -4,4\"/>\n",
       "<!-- Class Amount -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Class Amount</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"62.39\" cy=\"-162\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.39\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Class Amount</text>\n",
       "</g>\n",
       "<!-- Good Grade -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Good Grade</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"62.39\" cy=\"-18\" rx=\"55.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.39\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Good Grade</text>\n",
       "</g>\n",
       "<!-- Class Amount&#45;&gt;Good Grade -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Class Amount&#45;&gt;Good Grade</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.68,-143.83C49.02,-133.69 43.77,-120.44 41.39,-108 38.39,-92.28 38.39,-87.72 41.39,-72 43.1,-63.06 46.29,-53.7 49.68,-45.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"52.91,-46.73 53.68,-36.17 46.49,-43.95 52.91,-46.73\"/>\n",
       "</g>\n",
       "<!-- Study Time -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Study Time</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"103.39\" cy=\"-90\" rx=\"53.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.39\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Study Time</text>\n",
       "</g>\n",
       "<!-- Class Amount&#45;&gt;Study Time -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Class Amount&#45;&gt;Study Time</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.32,-144.05C77.15,-135.8 83.07,-125.7 88.44,-116.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.53,-118.19 93.56,-107.79 85.49,-114.65 91.53,-118.19\"/>\n",
       "</g>\n",
       "<!-- Study Time&#45;&gt;Good Grade -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Study Time&#45;&gt;Good Grade</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.47,-72.05C88.63,-63.8 82.72,-53.7 77.35,-44.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.3,-42.65 72.23,-35.79 74.26,-46.19 80.3,-42.65\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f98ec934dc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"Class Amount\",\"Good Grade\")\n",
    "g.edge(\"Study Time\",\"Good Grade\")\n",
    "g.edge(\"Class Amount\",\"Study Time\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59f96247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data3(tau,N,p,p0,corr,conf = True):\n",
    "    \"\"\"\n",
    "    p0(int): number of covariates with nonzero coefficients\n",
    "    \"\"\"\n",
    "    nvar = p+2 # 1 confounder and variable for randomizing treatment\n",
    "    corr = 0.5 # correlation for multivariate normal\n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "    else: \n",
    "        conf_mult=1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) # variable for RDD assignment\n",
    "    C = allX[:,1].reshape([N,1]) # confounder\n",
    "    X = allX[:,2:] # observed covariates\n",
    "    \n",
    "    T = fn_randomize_treatment(N) # choose treated units\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 # sparse model\n",
    "    Yab = tau*T+X@beta0+conf_mult*0.6*C+err\n",
    "    return (Yab,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7ad3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = 0.5\n",
    "conf=True\n",
    "p = 10\n",
    "p0=0\n",
    "Nrange = range(10,1000,5) # loop over N values\n",
    "Y,T,C=fn_generate_data3(tau,N,p,p0,corr,conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "213ee66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([Y,T,C],axis=1)\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('Part2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18454aee",
   "metadata": {},
   "source": [
    "# When N=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f531c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3082462348590584, 0.23478676539344248)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "Yexp,T = fn_generate_data(tau,N,10,0,corr,conf = True)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "# n_values = n_values + [N]\n",
    "# tauhats = tauhats + [tauhat]\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ee2f4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   96.65</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>2.81e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:36</td>     <th>  Log-Likelihood:    </th> <td> -156.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   317.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   323.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.3082</td> <td>    0.235</td> <td>    9.831</td> <td> 0.000</td> <td>    1.842</td> <td>    2.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.3503</td> <td>    0.166</td> <td>   -2.110</td> <td> 0.037</td> <td>   -0.680</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.158</td> <th>  Durbin-Watson:     </th> <td>   2.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.924</td> <th>  Jarque-Bera (JB):  </th> <td>   0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.078</td> <th>  Prob(JB):          </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.950</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.497\n",
       "Model:                            OLS   Adj. R-squared:                  0.491\n",
       "Method:                 Least Squares   F-statistic:                     96.65\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):           2.81e-16\n",
       "Time:                        01:03:36   Log-Likelihood:                -156.92\n",
       "No. Observations:                 100   AIC:                             317.8\n",
       "Df Residuals:                      98   BIC:                             323.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             2.3082      0.235      9.831      0.000       1.842       2.774\n",
       "const         -0.3503      0.166     -2.110      0.037      -0.680      -0.021\n",
       "==============================================================================\n",
       "Omnibus:                        0.158   Durbin-Watson:                   2.224\n",
       "Prob(Omnibus):                  0.924   Jarque-Bera (JB):                0.112\n",
       "Skew:                          -0.078   Prob(JB):                        0.946\n",
       "Kurtosis:                       2.950   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.ones([N,1])\n",
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8106b8fe",
   "metadata": {},
   "source": [
    "# When N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ece8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1030109583937664, 0.06545280382710945)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "Yexp,T = fn_generate_data(tau,N,10,0,corr,conf = True)\n",
    "Yt = Yexp[np.where(T==1)[0],:]\n",
    "Yc = Yexp[np.where(T==0)[0],:]\n",
    "tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "lb = lb + [tauhat-1.96*se_tauhat]\n",
    "ub = ub + [tauhat+1.96*se_tauhat]\n",
    "tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0e283b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.508</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.508</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1032.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 15 Apr 2022</td> <th>  Prob (F-statistic):</th> <td>4.34e-156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:03:36</td>     <th>  Log-Likelihood:    </th> <td> -1452.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   2908.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   2918.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.1030</td> <td>    0.065</td> <td>   32.130</td> <td> 0.000</td> <td>    1.975</td> <td>    2.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0365</td> <td>    0.046</td> <td>   -0.790</td> <td> 0.430</td> <td>   -0.127</td> <td>    0.054</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.368</td> <th>  Durbin-Watson:     </th> <td>   1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.832</td> <th>  Jarque-Bera (JB):  </th> <td>   0.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.027</td> <th>  Prob(JB):          </th> <td>   0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.911</td> <th>  Cond. No.          </th> <td>    2.62</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.508\n",
       "Model:                            OLS   Adj. R-squared:                  0.508\n",
       "Method:                 Least Squares   F-statistic:                     1032.\n",
       "Date:                Fri, 15 Apr 2022   Prob (F-statistic):          4.34e-156\n",
       "Time:                        01:03:36   Log-Likelihood:                -1452.2\n",
       "No. Observations:                1000   AIC:                             2908.\n",
       "Df Residuals:                     998   BIC:                             2918.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             2.1030      0.065     32.130      0.000       1.975       2.231\n",
       "const         -0.0365      0.046     -0.790      0.430      -0.127       0.054\n",
       "==============================================================================\n",
       "Omnibus:                        0.368   Durbin-Watson:                   1.980\n",
       "Prob(Omnibus):                  0.832   Jarque-Bera (JB):                0.453\n",
       "Skew:                          -0.027   Prob(JB):                        0.797\n",
       "Kurtosis:                       2.911   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const = np.ones([N,1])\n",
    "model = sm.OLS(Yexp,np.concatenate([T,const],axis = 1))\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c1122",
   "metadata": {},
   "source": [
    "# Run a Monte Carlo experiment, and calculate the bias, RMSE and size for N=100 and N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ed43fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:02<00:00, 847.11it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:12<00:00, 161.17it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,C = fn_generate_data3(tau,N,10,0,corr,conf=True)\n",
    "        covars = np.concatenate([T],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb87d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.0070224888824297034, RMSE=0.16590449885781594, size=0.064\n",
      "N=1000: bias=0.0008851637151934284, RMSE=0.051784513849357124, size=0.0525\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795c155",
   "metadata": {},
   "source": [
    "# 2b Experiments have control for confounder  in the DGP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec234965",
   "metadata": {},
   "source": [
    "# Run a Monte Carlo experiment, and calculate the bias, RMSE and size for N=100 and N=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff2347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1028.69it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:12<00:00, 165.01it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,C = fn_generate_data3(tau,N,p,30,corr,conf=True)\n",
    "        covars = np.concatenate([T,C],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e2da680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.08093251593354253, RMSE=4.485453808051431, size=0.065\n",
      "N=1000: bias=0.009609427008887032, RMSE=1.3836842440877082, size=0.053\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f2894",
   "metadata": {},
   "source": [
    "# 3a Do not control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d44dabb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.1 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"148pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 148.04 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 144.04,-184 144.04,4 -4,4\"/>\n",
       "<!-- Confounder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Confounder</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.1\" cy=\"-162\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.1\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Confounder</text>\n",
       "</g>\n",
       "<!-- Treatment -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Treatment</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"48.1\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"48.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Treatment</text>\n",
       "</g>\n",
       "<!-- Confounder&#45;&gt;Treatment -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Confounder&#45;&gt;Treatment</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M76.9,-144.05C72.46,-135.89 67.05,-125.91 62.11,-116.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.06,-114.91 57.21,-107.79 58.9,-118.25 65.06,-114.91\"/>\n",
       "</g>\n",
       "<!-- Outcome -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Outcome</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86.1\" cy=\"-18\" rx=\"44.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"86.1\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Outcome</text>\n",
       "</g>\n",
       "<!-- Confounder&#45;&gt;Outcome -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Confounder&#45;&gt;Outcome</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.99,-143.75C98.2,-133.58 102.95,-120.33 105.1,-108 107.84,-92.24 107.84,-87.76 105.1,-72 103.53,-63 100.58,-53.51 97.46,-45.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.71,-43.8 93.79,-35.78 94.2,-46.37 100.71,-43.8\"/>\n",
       "</g>\n",
       "<!-- Treatment&#45;&gt;Outcome -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Treatment&#45;&gt;Outcome</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.29,-72.05C61.73,-63.89 67.14,-53.91 72.08,-44.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.29,-46.25 76.98,-35.79 69.13,-42.91 75.29,-46.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f98ec90e400>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"Confounder\",\"Treatment\")\n",
    "g.edge(\"Confounder\",\"Outcome\")\n",
    "g.edge(\"Treatment\",\"Outcome\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dda339b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data4(tau,N,p,corr):\n",
    "\n",
    "    nvar = p+1 \n",
    "    corr = 0.6 \n",
    " \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    U = np.random.normal(0,1,[N,1])\n",
    "    Y = tau*T+err\n",
    "    S = 2*T+0.6*Y+U\n",
    "\n",
    "    return (Y,T,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12552e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = 0.6\n",
    "p = 2\n",
    "N = 1000\n",
    "Y,T,S = fn_generate_data4(tau,N,p,corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca11ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([Y,T,S],axis = 1)\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('dataselectionbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2635f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 3184.76it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:09<00:00, 211.90it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T,Z = fn_generate_data4(tau,N,p,corr)   \n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e169439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.005371551344162723, RMSE=0.20137743983885265, size=0.055\n",
      "N=1000: bias=0.001986601607253292, RMSE=0.06244782103554409, size=0.04\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8f8ff",
   "metadata": {},
   "source": [
    "# 3b Have control for selection bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "933b8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1242.74it/s]\n",
      "100%|██████████████████████████████████████| 2000/2000 [00:10<00:00, 186.59it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 2000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T,Z = fn_generate_data4(tau,N,p,corr)\n",
    "        covars = np.concatenate([T,Z],axis = 1)\n",
    "        mod = sm.OLS(Yexp,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_tauhat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d0eea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-1.4086110609715208, RMSE=1.4327532130406704, size=0.999\n",
      "N=1000: bias=-1.4100147062334325, RMSE=1.4126633811516796, size=1.0\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c0902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8cfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
